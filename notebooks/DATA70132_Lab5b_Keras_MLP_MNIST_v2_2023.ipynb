{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWWn1oMdMP0d"
      },
      "source": [
        "MLP for Complex Problems: The MNIST dataset\n",
        "=========\n",
        "\n",
        "\n",
        "In this exercise we will first learn to use the simple perceptron network (input-output layers only) and a Multi-Layer Perceptron (MLP, with one or more hidden layers). To make the task more interesting than the XOR problem, we will be using a more complex training set. This will be the MNIST dataset, a well known neural network problem for the recognition of the 10 handwritten characters from 0 to 9 ([MNIST](http://yann.lecun.com/exdb/mnist/)).\n",
        "\n",
        "This exercise is based on the  Gulli & Pal (2017) 'Deep Learning with Keras' textbook, with some additional code to help us understand and test the programme.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezwPEU5UMP0o"
      },
      "source": [
        "**Importing the libraries and defining the main training parameters**\n",
        "\n",
        "The initial code is necessary to prepare the data and the simulation (hyper)parameters.\n",
        "We first import numpy. In our case we will use it to create and pre-process the array of the training data sets. We then import a few functions from Keras (we used some of these in our previous XOR exercise). The matplotlib library will be used for visualising some MNIST images and the plot of the training results.\n",
        "\n",
        "The code also defines the variables for some of the main parameters used throughout this program. \n",
        "The random seed definition is also important to be able to repeat the same parameter configuration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "YpM98ckGMP0u"
      },
      "outputs": [],
      "source": [
        "# import of numpy and keras libraries\n",
        "from __future__ import print_function\n",
        "import numpy as np\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation\n",
        "from tensorflow.keras.optimizers.legacy import SGD\n",
        "from tensorflow.keras import utils\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# variables for network and training\n",
        "N_EPOCH = 200 # initially set at 200 ; you can change this later \n",
        "BATCH_SIZE = 128  \n",
        "VERBOSE = 1\n",
        "N_CLASSES = 10   # number of classes/categories of digits from 0 to 9, i.e. number of output units \n",
        "OPTIMIZER = SGD(learning_rate=0.1) # Stochastic gradient descent optimiser\n",
        "N_HIDDEN = 128   # number of hidden units\n",
        "VALIDATION_SPLIT=0.2 # proportion of the dataset used for validation, with remaining .8 for training \n",
        "\n",
        "#each 2D image consists of 28x28 values/pixels, which needs to be reshaped in a vector of 784 pixels\n",
        "RESHAPED = 784\n",
        "\n",
        "# random seed number to be used for reproducibility\n",
        "np.random.seed(1671)  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rgZEImMMP08"
      },
      "source": [
        "**Preparing the MNIST dataset and visualising the input images**\n",
        "\n",
        "This part of the code prepares the input and output training set, and the corresponding test sets. \n",
        "It also visualises a sample image. The MNIST dataset is included in the Keras program and we do not need to use and external file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "l4-TuW2_MP0-",
        "outputId": "89fbc4e9-f9c5-460c-d2c6-6831b05e1f09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 1s 0us/step\n",
            "Training data input shape:  (60000, 28, 28)\n",
            "Training data output shape:  (60000,)\n",
            "Test data input shape:  (10000, 28, 28)\n",
            "Test data ouput shape:  (10000,)\n",
            "Sample input image: [[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0  67 232  39   0   0   0   0   0]\n",
            " [  0   0   0   0  62  81   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0 120 180  39   0   0   0   0   0]\n",
            " [  0   0   0   0 126 163   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   2 153 210  40   0   0   0   0   0]\n",
            " [  0   0   0   0 220 163   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0  27 254 162   0   0   0   0   0   0]\n",
            " [  0   0   0   0 222 163   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0 183 254 125   0   0   0   0   0   0]\n",
            " [  0   0   0  46 245 163   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0 198 254  56   0   0   0   0   0   0]\n",
            " [  0   0   0 120 254 163   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   23 231 254  29   0   0   0   0   0   0]\n",
            " [  0   0   0 159 254 120   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "  163 254 216  16   0   0   0   0   0   0]\n",
            " [  0   0   0 159 254  67   0   0   0   0   0   0   0   0   0  14  86 178\n",
            "  248 254  91   0   0   0   0   0   0   0]\n",
            " [  0   0   0 159 254  85   0   0   0  47  49 116 144 150 241 243 234 179\n",
            "  241 252  40   0   0   0   0   0   0   0]\n",
            " [  0   0   0 150 253 237 207 207 207 253 254 250 240 198 143  91  28   5\n",
            "  233 250   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0 119 177 177 177 177 177  98  56   0   0   0   0   0 102\n",
            "  254 220   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 169\n",
            "  254 137   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 169\n",
            "  254  57   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 169\n",
            "  254  57   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 169\n",
            "  255  94   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 169\n",
            "  254  96   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 169\n",
            "  254 153   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 169\n",
            "  255 153   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  96\n",
            "  254 153   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "\n",
        "# data: shuffled and split between train and test sets, loading and using the Keras mnist dataset\n",
        "(input_X_train, output_Y_train), (input_X_test, output_Y_test) = mnist.load_data()\n",
        "\n",
        "# print the shapes of the input and output data\n",
        "print(\"Training data input shape: \" , input_X_train.shape)\n",
        "print(\"Training data output shape: \" , output_Y_train.shape)\n",
        "print(\"Test data input shape: \" , input_X_test.shape)\n",
        "print(\"Test data ouput shape: \" , output_Y_test.shape)\n",
        "\n",
        "# visualisation of the numerical vector and plot of a selected image\n",
        "Selected_Image = 2\n",
        "image = input_X_train[Selected_Image]\n",
        "print (\"Sample input image: \" + str(image))\n",
        "plt.imshow(image, cmap='gray')\n",
        "plt.show() \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDqNl3taMP1P"
      },
      "source": [
        "The input images now have to be reshaped as a linear vector. That is, we go from a 2D image of 28x28 pixels, to a linear vector of 784 (i.e. 28*28) pixels, to be passed as the 784 input units. Moreover, the initial pixel grey values given as type __int__ in the range 0-255 will be normalised to the __float32__ type in the range 0-1. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fB15FrXOMP1R",
        "outputId": "967d8aef-42c7-45eb-8a7a-5f44fb4fe7ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data ready\n"
          ]
        }
      ],
      "source": [
        "# use 60000 images for training, 10000 for validation test\n",
        "input_X_train = input_X_train.reshape(60000, RESHAPED)\n",
        "input_X_test = input_X_test.reshape(10000, RESHAPED)\n",
        "input_X_train = input_X_train.astype('float32')\n",
        "input_X_test = input_X_test.astype('float32')\n",
        "\n",
        "# normalisation of the pixel values from 0-255 range to 0-1 range \n",
        "input_X_train /= 255\n",
        "input_X_test /= 255\n",
        "\n",
        "print (\"Input data ready\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KsCwC5y7MP1Z"
      },
      "source": [
        "**Preparing the output labels**\n",
        "\n",
        "This code converts the output data into categorical (one-hot encoding) vectors of 0s and 1s.\n",
        "See example of the visualisation of the one-hot vector for the selected image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rc4dgAqqMP1c",
        "outputId": "dd676410-e919-4bf7-b6e9-08d10a5fefe0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "One-hot-vector: [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ],
      "source": [
        "# convert class vectors to binary class matrices\n",
        "output_Y_train = utils.to_categorical(output_Y_train, N_CLASSES)\n",
        "output_Y_test = utils.to_categorical(output_Y_test, N_CLASSES)\n",
        "\n",
        "# print the categorical, one-hot output vector for the sample image\n",
        "label = output_Y_train[Selected_Image]\n",
        "print (\"One-hot-vector: \" + str(label))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-rcBfv8MP1q"
      },
      "source": [
        "Training the Simple Perceptron\n",
        "=========\n",
        "\n",
        "**Defining the network: Simple Perceptron**\n",
        "\n",
        "We will start by training a simple perceptron, i.e. a network with an input layer (the 784 input values/pixels) connected to the output layer (the 10 number classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTb4RC7zMP1s",
        "outputId": "28758ce9-9f80-4cea-9197-853195fed760"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 10)                7850      \n",
            "                                                                 \n",
            " activation (Activation)     (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,850\n",
            "Trainable params: 7,850\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Defaults sequential model\n",
        "model = Sequential()\n",
        "\n",
        "# Dense layer for all to all connections\n",
        "# Define the output layer with 10 output units, and softmax activation as categorical output\n",
        "model.add(Dense(N_CLASSES, input_shape=(RESHAPED,)))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "# Use categorical crossentropy for the loss evaluation, and the accuracy metrics\n",
        "# we previously chose the SGD optimiser in the OPTIMIZER variable definition  \n",
        "model.compile(loss='categorical_crossentropy', optimizer=OPTIMIZER, metrics=['accuracy'])\n",
        "\n",
        "#show the model summary\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHyq0YoRMP1y"
      },
      "source": [
        "**Let's train the simple perceptron network**\n",
        "\n",
        "Let's now train (fit) the network with the above-defined batch size (128), and number of epochs (200). We save the training results into the history variable.\n",
        "\n",
        "Here we use the previous __VALIDATION_SPLIT=0.2__ definition to split the dataset into a 20% (0.2) validation set and the remaning 80% as training set. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lg3RCFukMP10",
        "outputId": "7234ab20-e116-4998-822f-281622625dba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "375/375 [==============================] - 12s 29ms/step - loss: 0.6275 - accuracy: 0.8425 - val_loss: 0.3968 - val_accuracy: 0.8957\n",
            "Epoch 2/200\n",
            "375/375 [==============================] - 5s 14ms/step - loss: 0.3964 - accuracy: 0.8925 - val_loss: 0.3483 - val_accuracy: 0.9053\n",
            "Epoch 3/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3596 - accuracy: 0.9000 - val_loss: 0.3265 - val_accuracy: 0.9096\n",
            "Epoch 4/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3405 - accuracy: 0.9050 - val_loss: 0.3164 - val_accuracy: 0.9122\n",
            "Epoch 5/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3285 - accuracy: 0.9082 - val_loss: 0.3070 - val_accuracy: 0.9149\n",
            "Epoch 6/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.3197 - accuracy: 0.9114 - val_loss: 0.3022 - val_accuracy: 0.9141\n",
            "Epoch 7/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.3129 - accuracy: 0.9127 - val_loss: 0.2971 - val_accuracy: 0.9172\n",
            "Epoch 8/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3075 - accuracy: 0.9141 - val_loss: 0.2933 - val_accuracy: 0.9180\n",
            "Epoch 9/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3034 - accuracy: 0.9155 - val_loss: 0.2903 - val_accuracy: 0.9187\n",
            "Epoch 10/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2996 - accuracy: 0.9169 - val_loss: 0.2879 - val_accuracy: 0.9199\n",
            "Epoch 11/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2962 - accuracy: 0.9178 - val_loss: 0.2879 - val_accuracy: 0.9200\n",
            "Epoch 12/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2933 - accuracy: 0.9186 - val_loss: 0.2876 - val_accuracy: 0.9194\n",
            "Epoch 13/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2912 - accuracy: 0.9190 - val_loss: 0.2839 - val_accuracy: 0.9208\n",
            "Epoch 14/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2889 - accuracy: 0.9201 - val_loss: 0.2823 - val_accuracy: 0.9214\n",
            "Epoch 15/200\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.2869 - accuracy: 0.9198 - val_loss: 0.2808 - val_accuracy: 0.9214\n",
            "Epoch 16/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2851 - accuracy: 0.9207 - val_loss: 0.2800 - val_accuracy: 0.9218\n",
            "Epoch 17/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2835 - accuracy: 0.9216 - val_loss: 0.2781 - val_accuracy: 0.9232\n",
            "Epoch 18/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2821 - accuracy: 0.9211 - val_loss: 0.2771 - val_accuracy: 0.9227\n",
            "Epoch 19/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2806 - accuracy: 0.9224 - val_loss: 0.2765 - val_accuracy: 0.9220\n",
            "Epoch 20/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2793 - accuracy: 0.9222 - val_loss: 0.2756 - val_accuracy: 0.9241\n",
            "Epoch 21/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2782 - accuracy: 0.9229 - val_loss: 0.2754 - val_accuracy: 0.9233\n",
            "Epoch 22/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2770 - accuracy: 0.9230 - val_loss: 0.2747 - val_accuracy: 0.9240\n",
            "Epoch 23/200\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.2758 - accuracy: 0.9235 - val_loss: 0.2747 - val_accuracy: 0.9224\n",
            "Epoch 24/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2747 - accuracy: 0.9235 - val_loss: 0.2739 - val_accuracy: 0.9243\n",
            "Epoch 25/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2738 - accuracy: 0.9236 - val_loss: 0.2736 - val_accuracy: 0.9233\n",
            "Epoch 26/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2730 - accuracy: 0.9240 - val_loss: 0.2732 - val_accuracy: 0.9244\n",
            "Epoch 27/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2722 - accuracy: 0.9244 - val_loss: 0.2735 - val_accuracy: 0.9229\n",
            "Epoch 28/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2712 - accuracy: 0.9244 - val_loss: 0.2716 - val_accuracy: 0.9251\n",
            "Epoch 29/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2705 - accuracy: 0.9248 - val_loss: 0.2712 - val_accuracy: 0.9237\n",
            "Epoch 30/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2699 - accuracy: 0.9246 - val_loss: 0.2716 - val_accuracy: 0.9243\n",
            "Epoch 31/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2692 - accuracy: 0.9252 - val_loss: 0.2712 - val_accuracy: 0.9246\n",
            "Epoch 32/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2684 - accuracy: 0.9255 - val_loss: 0.2707 - val_accuracy: 0.9251\n",
            "Epoch 33/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2677 - accuracy: 0.9255 - val_loss: 0.2700 - val_accuracy: 0.9247\n",
            "Epoch 34/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2671 - accuracy: 0.9257 - val_loss: 0.2702 - val_accuracy: 0.9240\n",
            "Epoch 35/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2667 - accuracy: 0.9256 - val_loss: 0.2695 - val_accuracy: 0.9249\n",
            "Epoch 36/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2657 - accuracy: 0.9263 - val_loss: 0.2711 - val_accuracy: 0.9247\n",
            "Epoch 37/200\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.2655 - accuracy: 0.9262 - val_loss: 0.2694 - val_accuracy: 0.9262\n",
            "Epoch 38/200\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 0.2649 - accuracy: 0.9259 - val_loss: 0.2688 - val_accuracy: 0.9258\n",
            "Epoch 39/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2642 - accuracy: 0.9266 - val_loss: 0.2687 - val_accuracy: 0.9258\n",
            "Epoch 40/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2638 - accuracy: 0.9263 - val_loss: 0.2682 - val_accuracy: 0.9266\n",
            "Epoch 41/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2634 - accuracy: 0.9266 - val_loss: 0.2681 - val_accuracy: 0.9259\n",
            "Epoch 42/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2628 - accuracy: 0.9268 - val_loss: 0.2688 - val_accuracy: 0.9250\n",
            "Epoch 43/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2622 - accuracy: 0.9266 - val_loss: 0.2681 - val_accuracy: 0.9269\n",
            "Epoch 44/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2618 - accuracy: 0.9274 - val_loss: 0.2691 - val_accuracy: 0.9252\n",
            "Epoch 45/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2613 - accuracy: 0.9274 - val_loss: 0.2682 - val_accuracy: 0.9255\n",
            "Epoch 46/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2612 - accuracy: 0.9271 - val_loss: 0.2675 - val_accuracy: 0.9274\n",
            "Epoch 47/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2605 - accuracy: 0.9275 - val_loss: 0.2695 - val_accuracy: 0.9266\n",
            "Epoch 48/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2602 - accuracy: 0.9278 - val_loss: 0.2690 - val_accuracy: 0.9252\n",
            "Epoch 49/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2600 - accuracy: 0.9277 - val_loss: 0.2674 - val_accuracy: 0.9268\n",
            "Epoch 50/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2596 - accuracy: 0.9277 - val_loss: 0.2674 - val_accuracy: 0.9265\n",
            "Epoch 51/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2592 - accuracy: 0.9284 - val_loss: 0.2673 - val_accuracy: 0.9263\n",
            "Epoch 52/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2586 - accuracy: 0.9280 - val_loss: 0.2682 - val_accuracy: 0.9264\n",
            "Epoch 53/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2583 - accuracy: 0.9281 - val_loss: 0.2679 - val_accuracy: 0.9273\n",
            "Epoch 54/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2579 - accuracy: 0.9284 - val_loss: 0.2681 - val_accuracy: 0.9262\n",
            "Epoch 55/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2578 - accuracy: 0.9279 - val_loss: 0.2670 - val_accuracy: 0.9265\n",
            "Epoch 56/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2573 - accuracy: 0.9277 - val_loss: 0.2669 - val_accuracy: 0.9270\n",
            "Epoch 57/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2571 - accuracy: 0.9280 - val_loss: 0.2672 - val_accuracy: 0.9273\n",
            "Epoch 58/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2567 - accuracy: 0.9282 - val_loss: 0.2676 - val_accuracy: 0.9267\n",
            "Epoch 59/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2564 - accuracy: 0.9284 - val_loss: 0.2671 - val_accuracy: 0.9284\n",
            "Epoch 60/200\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.2561 - accuracy: 0.9290 - val_loss: 0.2671 - val_accuracy: 0.9273\n",
            "Epoch 61/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2558 - accuracy: 0.9292 - val_loss: 0.2666 - val_accuracy: 0.9277\n",
            "Epoch 62/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2555 - accuracy: 0.9282 - val_loss: 0.2666 - val_accuracy: 0.9279\n",
            "Epoch 63/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2552 - accuracy: 0.9296 - val_loss: 0.2667 - val_accuracy: 0.9277\n",
            "Epoch 64/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2550 - accuracy: 0.9287 - val_loss: 0.2663 - val_accuracy: 0.9264\n",
            "Epoch 65/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2547 - accuracy: 0.9289 - val_loss: 0.2665 - val_accuracy: 0.9270\n",
            "Epoch 66/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2544 - accuracy: 0.9290 - val_loss: 0.2665 - val_accuracy: 0.9280\n",
            "Epoch 67/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2541 - accuracy: 0.9290 - val_loss: 0.2673 - val_accuracy: 0.9274\n",
            "Epoch 68/200\n",
            "183/375 [=============>................] - ETA: 0s - loss: 0.2542 - accuracy: 0.9308"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-3ef46e028cbe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#train the network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_X_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_Y_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mN_EPOCH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mVERBOSE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mVALIDATION_SPLIT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1654\u001b[0m                             \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1655\u001b[0m                             \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1656\u001b[0;31m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1657\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1658\u001b[0m                                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    474\u001b[0m         \"\"\"\n\u001b[1;32m    475\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"end\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"end\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    392\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m             \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1094\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1095\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1096\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1168\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1169\u001b[0m             \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1170\u001b[0;31m             \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1171\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    663\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 665\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    914\u001b[0m   \u001b[0mentries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mflat_structure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 916\u001b[0;31m   return pack_sequence_as(\n\u001b[0m\u001b[1;32m    917\u001b[0m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m       expand_composites=expand_composites)\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mpack_sequence_as\u001b[0;34m(structure, flat_sequence, expand_composites)\u001b[0m\n\u001b[1;32m    804\u001b[0m     \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcontains\u001b[0m \u001b[0ma\u001b[0m \u001b[0mdict\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mnon\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0msortable\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m   \"\"\"\n\u001b[0;32m--> 806\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_pack_sequence_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand_composites\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    807\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m_pack_sequence_as\u001b[0;34m(structure, flat_sequence, expand_composites, sequence_fn)\u001b[0m\n\u001b[1;32m    687\u001b[0m           \u001b[0;34m\"flat_sequence had %d items.  Structure: %s, flat_sequence: %s.\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m           (len(flat_structure), len(flat_sequence), structure, flat_sequence))\n\u001b[0;32m--> 689\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0msequence_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpacked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m_sequence_like\u001b[0;34m(instance, args)\u001b[0m\n\u001b[1;32m    207\u001b[0m       \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_collections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_factory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m       \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minstance_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m       \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#train the network\n",
        "history = model.fit(input_X_train, output_Y_train, batch_size=BATCH_SIZE, epochs=N_EPOCH, verbose=VERBOSE, validation_split=VALIDATION_SPLIT)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MpCg_YTMP17"
      },
      "source": [
        "**Looking at the results of the trained network**\n",
        "\n",
        "Let's evaluate the model to see how well it has learned ( or not) the MNIST problem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZN9rro7KMP19"
      },
      "outputs": [],
      "source": [
        "#test the network using the generalisation test dataset\n",
        "score = model.evaluate(input_X_test, output_Y_test, verbose=VERBOSE)\n",
        "print(\"\\nTest score/loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZuRJvfwMP2K"
      },
      "source": [
        "Training the Multi-Layer Perceptron\n",
        "=========\n",
        "**Defining the network: Multi-Layer Perceptron**\n",
        "\n",
        "We will now create a multi-layer perceptron with 784 input units, two hidden layers with 128 hidden units each, and an output layer with the 10 units.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HoF0ib-SMP2N"
      },
      "outputs": [],
      "source": [
        "N_EPOCH = 20 # we need fewer epoch than before, as the multi-layer percetpron can learn faster.\n",
        "N_HIDDEN = 128\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# Hidden layer 1 with 128 hidden units and ReLu activation function\n",
        "model.add(Dense(N_HIDDEN, input_shape=(RESHAPED,)))\n",
        "model.add(Activation('relu'))\n",
        "# Hidden layer 2 with 128 hidden units and ReLu activation function\n",
        "model.add(Dense(N_HIDDEN))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "# output layer with 10 units and softmax activation\n",
        "model.add(Dense(N_CLASSES))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "# Summary of the whole model\n",
        "model.summary()\n",
        "\n",
        "# model compilation\n",
        "model.compile(loss='categorical_crossentropy', optimizer=OPTIMIZER, metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgYzi3hyMP2V"
      },
      "source": [
        "**Let's train the mulri-layer perceptron network**\n",
        "\n",
        "Let's now train (fit) the network with the above-defined batch size (128), and number of epochs (20)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iNa3cmoaMP2X"
      },
      "outputs": [],
      "source": [
        "#train the network\n",
        "history = model.fit(input_X_train, output_Y_train, batch_size=BATCH_SIZE, epochs=N_EPOCH, verbose=VERBOSE, validation_split=VALIDATION_SPLIT)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kV5v4LNjMP2e"
      },
      "source": [
        "**Looking at the results of the trained network**\n",
        "\n",
        "Let's explotre the results both for the score and accuracy values, as well as to visualise the plots of these values during the training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CXpu8p9uMP2f"
      },
      "outputs": [],
      "source": [
        "#test the network\n",
        "score = model.evaluate(input_X_test, output_Y_test, verbose=VERBOSE)\n",
        "print(\"\\nTest score/loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yYRZkVf6MP2t"
      },
      "outputs": [],
      "source": [
        "# list all data in history\n",
        "print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MJ9YbKviMP2z"
      },
      "outputs": [],
      "source": [
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CV-aShF1MP24"
      },
      "source": [
        "**Adding weight droputs**\n",
        "\n",
        "An efficient way to reduce the number of parameters (weights) to be trained, as well as to increase generalisation capabilities, is to randomly remove (i.e. __dropout__) a certain proportion of the nodes at random in each epoch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4GNrMiVoMP25"
      },
      "outputs": [],
      "source": [
        "# import the dropout layer type\n",
        "from tensorflow.keras.layers import Dropout\n",
        "\n",
        "# Probability of weights dropout\n",
        "P_DROPOUT = 0.3\n",
        "\n",
        "# We can increse this parameter afterwards\n",
        "N_EPOCH = 20\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(N_HIDDEN, input_shape=(RESHAPED,)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(P_DROPOUT))\n",
        "model.add(Dense(N_HIDDEN))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(P_DROPOUT))\n",
        "model.add(Dense(N_CLASSES))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "# model compilation\n",
        "model.summary()\n",
        "\n",
        "# model compilation\n",
        "model.compile(loss='categorical_crossentropy', optimizer=OPTIMIZER, metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBJJWwueMP2-"
      },
      "source": [
        "**Let's train the multi-layer perceptron network with DROPOUT**\n",
        "\n",
        "Let's now train (fit) the above dropout network with the above-defined batch size (128), and number of epochs (250)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xqa-9UHxMP3A"
      },
      "outputs": [],
      "source": [
        "#train the network\n",
        "history = model.fit(input_X_train, output_Y_train, batch_size=BATCH_SIZE, epochs=N_EPOCH, verbose=VERBOSE, validation_split=VALIDATION_SPLIT)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-z1NP88MP3I"
      },
      "source": [
        "**Looking at the results of the trained dropout network**\n",
        "\n",
        "Let's explore the effects of adding the weight dropout on the network performance.\n",
        "\n",
        "You can see that the dropout has further improved our results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K8qIacDmMP3N"
      },
      "outputs": [],
      "source": [
        "#test the network\n",
        "score = model.evaluate(input_X_test, output_Y_test, verbose=VERBOSE)\n",
        "print(\"\\nTest score:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])\n",
        "\n",
        "# list all data in history\n",
        "print(history.history.keys())\n",
        "\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IUIcenlMP3S"
      },
      "source": [
        "Exploring Training Hyperparameters\n",
        "-------------\n",
        "\n",
        "You can explore the role of various hyperparameters to see how you can further improve the MLP model's performance on the MNIST dataset. \n",
        "\n",
        "For example, if you increase the number of epochs for the dropout network to 250, you will see that the test and train accuracy errors will converge (accuracy closer to 97% for both training and test), which means that we have achieved the best tradeoff between training and testing.\n",
        "\n",
        "You can carry out many additional simulations on hypeparameter exploration where you can try for example:\n",
        "\n",
        "- different number of epochs\n",
        "- different learning rate\n",
        "- different number of hidden nodes \n",
        "- different proportion of dropout rates \n",
        "- different optimisers in addition to SGD (e.g. RMSprop, Adam) \n",
        "- different batch size \n",
        "\n",
        "This final exercise will constitute the first neural network coursework. See Coursework specification documenty for more details.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPKj5NAdMP3T"
      },
      "source": [
        "Conclusions\n",
        "-------------\n",
        "\n",
        "With this tutorial we have practiced the training of both a Simple Perceptron, and a Multi-Layer Perceptron, with a benchmark dataset containing images of handwritten numbers.\n",
        "This helped us understand how to load the datase, visualise it, and visualise the training history and the effects of adding hidden layers and then adding weight dropout.\n",
        "\n",
        "**Copyright (c)** 2022 Angelo Cangelosi, MIT License. Code and examples adapted from Gulli & Pal (2017) Deep Learning with Keras. Punkt Publishing. With further contribution from Wenjie Huang."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}